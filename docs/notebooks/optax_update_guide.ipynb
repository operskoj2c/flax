{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Optax Update Guide",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Colab for\n",
        "https://flax.readthedocs.io/en/latest/howtos/optax_update_guide.html"
      ],
      "metadata": {
        "id": "dHMnJTK9R5n9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ],
      "metadata": {
        "id": "fCCY-S009eHv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q flax optax"
      ],
      "metadata": {
        "id": "I4PiwrnnO6Fw"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Sequence\n",
        "\n",
        "import flax\n",
        "from  flax.training import train_state\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import flax.linen as nn\n",
        "import optax"
      ],
      "metadata": {
        "id": "7hDWlLOOt4U6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = {\n",
        "    'image': jnp.ones([1, 28, 28, 1]),\n",
        "    'label': jnp.array([0]),\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mb2xGRAwueSa",
        "outputId": "30260605-6773-482d-be0e-0383e63b9fa2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron(nn.Module):\n",
        "  units: Sequence[int]\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    x = x.reshape([x.shape[0], -1]) / 255.\n",
        "    x = nn.Dense(50)(x)\n",
        "    x = nn.relu(x)\n",
        "    return nn.Dense(10)(x)\n",
        "\n",
        "def loss(params, batch):\n",
        "  logits = model.apply({'params': params}, batch['image'])\n",
        "  one_hot = jax.nn.one_hot(batch['label'], 10)\n",
        "  return jnp.mean(optax.softmax_cross_entropy(logits=logits, labels=one_hot))\n",
        "\n",
        "model = Perceptron([50, 10])\n",
        "variables = model.init(jax.random.PRNGKey(0), batch['image'])\n",
        "\n",
        "jax.tree_map(jnp.shape, variables)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lf11Nzj-t32w",
        "outputId": "c54a570b-d76a-43bb-f1ab-5cbbbfd6f584"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FrozenDict({\n",
              "    params: {\n",
              "        Dense_0: {\n",
              "            bias: (50,),\n",
              "            kernel: (784, 50),\n",
              "        },\n",
              "        Dense_1: {\n",
              "            bias: (10,),\n",
              "            kernel: (50, 10),\n",
              "        },\n",
              "    },\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKm0nn4X57Vg",
        "outputId": "e1794ea2-ea91-45b5-8b89-d39d2d923cc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "\n",
        "builder = tfds.builder('mnist')\n",
        "builder.download_and_prepare()\n",
        "ds_test = jax.tree_map(jnp.array, builder.as_dataset('test', batch_size=-1))\n",
        "get_ds_train = lambda: (\n",
        "    jax.tree_map(jnp.array, x)\n",
        "    for x in builder.as_dataset('train').batch(128))\n",
        "batch = next(get_ds_train())\n",
        "jax.tree_map(jnp.shape, batch)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_datasets/core/dataset_builder.py:598: get_single_element (from tensorflow.python.data.experimental.ops.get_single_element) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.get_single_element()`.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image': (128, 28, 28, 1), 'label': (128,)}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def eval(params):\n",
        "  logits = model.apply({'params': params}, ds_test['image'])\n",
        "  return (logits.argmax(axis=-1) == ds_test['label']).mean()\n",
        "\n",
        "eval(variables['params'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCceGZ_Kvko5",
        "outputId": "af1f8657-b3eb-4c9b-d073-48954481166b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(0.103, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate, momentum = 0.01, 0.9"
      ],
      "metadata": {
        "id": "rqQiq3ugxKjX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Replacing `flax.optim` with `optax`"
      ],
      "metadata": {
        "id": "JyXnY2WW9gfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def train_step(optimizer, batch):\n",
        "  grads = jax.grad(loss)(optimizer.target, batch)\n",
        "  return optimizer.apply_gradient(grads)\n",
        "\n",
        "optimizer = flax.optim.Momentum(learning_rate, momentum).create(\n",
        "    variables['params'])\n",
        "for batch in get_ds_train():\n",
        "  optimizer = train_step(optimizer, batch)\n",
        "\n",
        "eval(optimizer.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mlz-P5AwBc2",
        "outputId": "05cb4271-e407-4798-d0ea-cd8dfbd9f2a1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(0.9165, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def train_step(params, opt_state, batch):\n",
        "  grads = jax.grad(loss)(params, batch)\n",
        "  updates, opt_state = tx.update(grads, opt_state)\n",
        "  params = optax.apply_updates(params, updates)\n",
        "  return params, opt_state\n",
        "\n",
        "tx = optax.sgd(learning_rate, momentum)\n",
        "params = variables['params']\n",
        "opt_state = tx.init(params)\n",
        "\n",
        "for batch in get_ds_train():\n",
        "  params, opt_state = train_step(params, opt_state, batch)\n",
        "\n",
        "eval(params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9IxglwJxD3X",
        "outputId": "a42f9e8d-d1fe-4221-ec28-b7258174b16c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(0.9165, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@jax.jit\n",
        "def train_step(state, batch):\n",
        "  def loss(params):\n",
        "    logits = state.apply_fn({'params': params}, batch['image'])\n",
        "    one_hot = jax.nn.one_hot(batch['label'], 10)\n",
        "    return jnp.mean(optax.softmax_cross_entropy(logits=logits, labels=one_hot))\n",
        "  grads = jax.grad(loss)(state.params)\n",
        "  return state.apply_gradients(grads=grads)\n",
        "\n",
        "tx = optax.sgd(learning_rate, momentum)\n",
        "state = train_state.TrainState.create(\n",
        "    apply_fn=model.apply, tx=tx, params=variables['params'],\n",
        ")\n",
        "opt_state = tx.init(params)\n",
        "\n",
        "for batch in get_ds_train():\n",
        "  state = train_step(state, batch)\n",
        "\n",
        "eval(params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBcp17BEvBVs",
        "outputId": "dd912efc-669f-42c2-86b2-e242cecc67ce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(0.9165, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Composable Gradient Transformations"
      ],
      "metadata": {
        "id": "4ute1zBpRnaq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def train_step(params, opt_state, batch):\n",
        "  grads = jax.grad(loss)(params, batch)\n",
        "  updates, opt_state = tx.update(grads, opt_state)\n",
        "  params = optax.apply_updates(params, updates)\n",
        "  return params, opt_state\n",
        "\n",
        "tx = optax.chain(\n",
        "    optax.trace(decay=momentum),\n",
        "    optax.scale(-learning_rate),\n",
        ")\n",
        "params = variables['params']\n",
        "opt_state = tx.init(params)\n",
        "\n",
        "for batch in get_ds_train():\n",
        "  params, opt_state = train_step(params, opt_state, batch)\n",
        "\n",
        "eval(params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2WjJ7HT8GMn",
        "outputId": "7ae7117e-5d1d-44ca-abb8-65b0db2c0eb6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(0.9165, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weight Decay"
      ],
      "metadata": {
        "id": "vFt96TU-rSQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weight_decay = 1e-5"
      ],
      "metadata": {
        "id": "Qbq9vK24-omQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def train_step(optimizer, batch):\n",
        "  grads = jax.grad(loss)(optimizer.target, batch)\n",
        "  return optimizer.apply_gradient(grads)\n",
        "\n",
        "optimizer = flax.optim.Adam(learning_rate, weight_decay=weight_decay).create(\n",
        "    variables['params'])\n",
        "for batch in get_ds_train():\n",
        "  optimizer = train_step(optimizer, batch)\n",
        "\n",
        "eval(optimizer.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx1YCFVL9ktA",
        "outputId": "bb6795a7-c5c2-458a-d3e9-4b769b857fed"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(0.95129997, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def train_step(params, opt_state, batch):\n",
        "  grads = jax.grad(loss)(params, batch)\n",
        "  updates, opt_state = tx.update(grads, opt_state, params)\n",
        "  params = optax.apply_updates(params, updates)\n",
        "  return params, opt_state\n",
        "\n",
        "tx = optax.chain(\n",
        "    optax.scale_by_adam(),\n",
        "    optax.add_decayed_weights(weight_decay),\n",
        "    optax.scale(-learning_rate),\n",
        ")\n",
        "params = variables['params']\n",
        "opt_state = tx.init(params)\n",
        "\n",
        "for batch in get_ds_train():\n",
        "  params, opt_state = train_step(params, opt_state, batch)\n",
        "\n",
        "eval(params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIWCQz33-p98",
        "outputId": "84753c79-314b-4982-97e6-0c61a490eab1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(0.9517, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradient Clipping"
      ],
      "metadata": {
        "id": "MZE97FEbCgmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grad_clip_norm = 1.0"
      ],
      "metadata": {
        "id": "Y_DCoogODZL6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def train_step(optimizer, batch):\n",
        "  grads = jax.grad(loss)(optimizer.target, batch)\n",
        "  grads_flat, _ = jax.tree_flatten(grads)\n",
        "  global_l2 = jnp.sqrt(sum([jnp.vdot(p, p) for p in grads_flat]))\n",
        "  g_factor = jnp.minimum(1.0, grad_clip_norm / global_l2)\n",
        "  grads = jax.tree_map(lambda g: g * g_factor, grads)\n",
        "  return optimizer.apply_gradient(grads)\n",
        "\n",
        "optimizer = flax.optim.Momentum(learning_rate, momentum).create(\n",
        "    variables['params'])\n",
        "for batch in get_ds_train():\n",
        "  optimizer = train_step(optimizer, batch)\n",
        "\n",
        "eval(optimizer.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFnX8fb3Chwb",
        "outputId": "aae283d2-623e-4a43-c001-3e62b11483ae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(0.91679996, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def train_step(params, opt_state, batch):\n",
        "  grads = jax.grad(loss)(params, batch)\n",
        "  updates, opt_state = tx.update(grads, opt_state)\n",
        "  params = optax.apply_updates(params, updates)\n",
        "  return params, opt_state\n",
        "\n",
        "tx = optax.chain(\n",
        "    optax.clip_by_global_norm(grad_clip_norm),\n",
        "    optax.trace(decay=momentum),\n",
        "    optax.scale(-learning_rate),\n",
        ")\n",
        "params = variables['params']\n",
        "opt_state = tx.init(params)\n",
        "\n",
        "for batch in get_ds_train():\n",
        "  params, opt_state = train_step(params, opt_state, batch)\n",
        "\n",
        "eval(params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJYN2A-TDhp3",
        "outputId": "a9563d3a-7dc6-4ecf-bb7b-49356cf9fe13"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(0.91679996, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning Rate Schedules"
      ],
      "metadata": {
        "id": "d9e9YmNHE-xV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "schedule = lambda step: learning_rate * jnp.exp(step * 1e-3)"
      ],
      "metadata": {
        "id": "zCqz6fDsFB5n"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def train_step(step, optimizer, batch):\n",
        "  grads = jax.grad(loss)(optimizer.target, batch)\n",
        "  return step + 1, optimizer.apply_gradient(grads, learning_rate=schedule(step))\n",
        "\n",
        "optimizer = flax.optim.Momentum(learning_rate, momentum).create(\n",
        "    variables['params'])\n",
        "step = jnp.array(0)\n",
        "for batch in get_ds_train():\n",
        "  step, optimizer = train_step(step, optimizer, batch)\n",
        "\n",
        "eval(optimizer.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NinuzivVFYb5",
        "outputId": "c90b880e-d6f0-40fc-94b8-28d0622d8440"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(0.9201, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def train_step(params, opt_state, batch):\n",
        "  grads = jax.grad(loss)(params, batch)\n",
        "  updates, opt_state = tx.update(grads, opt_state)\n",
        "  params = optax.apply_updates(params, updates)\n",
        "  return params, opt_state\n",
        "\n",
        "tx = optax.chain(\n",
        "    optax.trace(decay=momentum),\n",
        "    optax.scale_by_schedule(lambda step: -schedule(step)),\n",
        ")\n",
        "params = variables['params']\n",
        "opt_state = tx.init(params)\n",
        "\n",
        "for batch in get_ds_train():\n",
        "  params, opt_state = train_step(params, opt_state, batch)\n",
        "\n",
        "eval(params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzaYwXzuFp-L",
        "outputId": "0ed7f41f-cc2d-46c6-ae9f-4be5b906fb7f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(0.9201, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multiple Optimizers"
      ],
      "metadata": {
        "id": "HLkQDKK0GCHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def train_step(optimizer, batch):\n",
        "  grads = jax.grad(loss)(optimizer.target, batch)\n",
        "  return optimizer.apply_gradient(grads)\n",
        "\n",
        "kernels = flax.traverse_util.ModelParamTraversal(lambda p, _: 'kernel' in p)\n",
        "biases = flax.traverse_util.ModelParamTraversal(lambda p, _: 'bias' in p)\n",
        "kernel_opt = flax.optim.Momentum(learning_rate, momentum)\n",
        "bias_opt = flax.optim.Momentum(learning_rate * 0.1, momentum)\n",
        "optimizer = flax.optim.MultiOptimizer(\n",
        "    (kernels, kernel_opt),\n",
        "    (biases, bias_opt)\n",
        ").create(variables['params'])\n",
        "\n",
        "for batch in get_ds_train():\n",
        "  optimizer = train_step(optimizer, batch)\n",
        "\n",
        "eval(optimizer.target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-2veL8lGDbV",
        "outputId": "b006d3cc-eff6-410a-e201-ccd9464db9d7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(0.91679996, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def train_step(params, opt_state, batch):\n",
        "  grads = jax.grad(loss)(params, batch)\n",
        "  updates, opt_state = tx.update(grads, opt_state)\n",
        "  params = optax.apply_updates(params, updates)\n",
        "  return params, opt_state\n",
        "\n",
        "kernels = flax.traverse_util.ModelParamTraversal(lambda p, _: 'kernel' in p)\n",
        "biases = flax.traverse_util.ModelParamTraversal(lambda p, _: 'bias' in p)\n",
        "\n",
        "all_false = jax.tree_map(lambda _: False, params)\n",
        "kernels_mask = kernels.update(lambda _: True, all_false)\n",
        "biases_mask = biases.update(lambda _: True, all_false)\n",
        "\n",
        "tx = optax.chain(\n",
        "    optax.trace(decay=momentum),\n",
        "    optax.masked(optax.scale(-learning_rate), kernels_mask),\n",
        "    optax.masked(optax.scale(-learning_rate * 0.1), biases_mask),\n",
        ")\n",
        "params = variables['params']\n",
        "opt_state = tx.init(params)\n",
        "\n",
        "for batch in get_ds_train():\n",
        "  params, opt_state = train_step(params, opt_state, batch)\n",
        "\n",
        "eval(params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvQlkiCuHr41",
        "outputId": "88b4b0dd-4b80-4c5b-c21d-803c097b8cc6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(0.91679996, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def train_step(params, opt_state, batch):\n",
        "  grads = jax.grad(loss)(params, batch)\n",
        "  updates, opt_state = tx.update(grads, opt_state)\n",
        "  params = optax.apply_updates(params, updates)\n",
        "  return params, opt_state\n",
        "\n",
        "kernels = flax.traverse_util.ModelParamTraversal(lambda p, _: 'kernel' in p)\n",
        "biases = flax.traverse_util.ModelParamTraversal(lambda p, _: 'bias' in p)\n",
        "\n",
        "all_false = jax.tree_map(lambda _: False, params)\n",
        "kernels_mask = kernels.update(lambda _: True, all_false)\n",
        "biases_mask = biases.update(lambda _: True, all_false)\n",
        "\n",
        "tx = optax.chain(\n",
        "    optax.trace(decay=momentum),\n",
        "    optax.multi_transform({\n",
        "      'kernels': optax.scale(-learning_rate),\n",
        "      'biases': optax.scale(-learning_rate * 0.1),\n",
        "  }, kernels.update(lambda _: 'kernels',\n",
        "                    biases.update(lambda _: 'biases', params))),\n",
        ")\n",
        "params = variables['params']\n",
        "opt_state = tx.init(params)\n",
        "\n",
        "for batch in get_ds_train():\n",
        "  params, opt_state = train_step(params, opt_state, batch)\n",
        "\n",
        "eval(params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2omX108JYDo",
        "outputId": "a9f45c8c-0db5-4b5e-b429-e6d79b22eca0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(0.91679996, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}