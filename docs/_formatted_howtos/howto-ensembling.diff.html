<div class="highlight-default notranslate"><div class="highlight">
<pre class="code">
<span style="background-color: rgba(255, 0, 0, 0.3)"><span class="o">---</span> <span class="n">a</span><span class="o">/</span><span class="n">examples</span><span class="o">/</span><span class="n">mnist</span><span class="o">/</span><span class="n">train</span><span class="o">.</span><span class="n">py</span></span>
<span style="background-color: rgba(0, 255, 0, 0.3)"><span class="o">+++</span> <span class="n">b</span><span class="o">/</span><span class="n">examples</span><span class="o">/</span><span class="n">mnist</span><span class="o">/</span><span class="n">train</span><span class="o">.</span><span class="n">py</span></span>
<span style="background-color: rgba(128, 128, 128, 0.3)">[...]</span>
 <span class="kn">from</span> <span class="nn">absl</span> <span class="kn">import</span> <span class="n">flags</span>
 <span class="kn">from</span> <span class="nn">absl</span> <span class="kn">import</span> <span class="n">logging</span>
 
<span style="background-color: rgba(0, 255, 0, 0.3)"><span class="o">+</span><span class="kn">import</span> <span class="nn">functools</span></span>
<span style="background-color: rgba(0, 255, 0, 0.3)"><span class="o">+</span></span>
<span style="background-color: rgba(0, 255, 0, 0.3)"><span class="o">+</span><span class="kn">from</span> <span class="nn">flax</span> <span class="kn">import</span> <span class="n">jax_utils</span></span>
 <span class="kn">from</span> <span class="nn">flax</span> <span class="kn">import</span> <span class="n">nn</span>
 <span class="kn">from</span> <span class="nn">flax</span> <span class="kn">import</span> <span class="n">optim</span>
 
<span style="background-color: rgba(128, 128, 128, 0.3)">[...]</span>
 <span class="k">def</span> <span class="nf">create_optimizer</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span> <span class="n">beta</span><span class="p">):</span>
   <span class="n">optimizer_def</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Momentum</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">)</span>
   <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer_def</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span style="background-color: rgba(0, 255, 0, 0.3)"><span class="o">+</span>  <span class="n">optimizer</span> <span class="o">=</span> <span class="n">jax_utils</span><span class="o">.</span><span class="n">replicate</span><span class="p">(</span><span class="n">optimizer</span><span class="p">)</span></span>
   <span class="k">return</span> <span class="n">optimizer</span>
 
<span style="background-color: rgba(128, 128, 128, 0.3)">[...]</span>
   <span class="k">return</span> <span class="o">-</span><span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">onehot</span><span class="p">(</span><span class="n">labels</span><span class="p">)</span> <span class="o">*</span> <span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
 
<span style="background-color: rgba(0, 255, 0, 0.3)"><span class="o">+</span><span class="k">def</span> <span class="nf">shard</span><span class="p">(</span><span class="n">xs</span><span class="p">):</span></span>
<span style="background-color: rgba(0, 255, 0, 0.3)"><span class="o">+</span>  <span class="k">return</span> <span class="n">jax</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span></span>
<span style="background-color: rgba(0, 255, 0, 0.3)"><span class="o">+</span>      <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">jax</span><span class="o">.</span><span class="n">device_count</span><span class="p">(),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:]),</span> <span class="n">xs</span><span class="p">)</span></span>
<span style="background-color: rgba(0, 255, 0, 0.3)"><span class="o">+</span></span>
 <span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
   <span class="n">loss</span> <span class="o">=</span> <span class="n">cross_entropy_loss</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
   <span class="n">accuracy</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">jnp</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="n">labels</span><span class="p">)</span>
<span style="background-color: rgba(128, 128, 128, 0.3)">[...]</span>
   <span class="k">return</span> <span class="n">metrics</span>
 
<span style="background-color: rgba(255, 0, 0, 0.3)"><span class="o">-</span><span class="nd">@jax</span><span class="o">.</span><span class="n">jit</span></span>
<span style="background-color: rgba(0, 255, 0, 0.3)"><span class="o">+</span><span class="nd">@functools</span><span class="o">.</span><span class="n">partial</span><span class="p">(</span><span class="n">jax</span><span class="o">.</span><span class="n">pmap</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="s1">&#39;batch&#39;</span><span class="p">)</span></span>
 <span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
   <span class="sd">&quot;&quot;&quot;Train for a single step.&quot;&quot;&quot;</span>
   <span class="k">def</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
<span style="background-color: rgba(128, 128, 128, 0.3)">[...]</span>
     <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">logits</span>
   <span class="n">grad_fn</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">value_and_grad</span><span class="p">(</span><span class="n">loss_fn</span><span class="p">,</span> <span class="n">has_aux</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
   <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">logits</span><span class="p">),</span> <span class="n">grad</span> <span class="o">=</span> <span class="n">grad_fn</span><span class="p">(</span><span class="n">optimizer</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
<span style="background-color: rgba(0, 255, 0, 0.3)"><span class="o">+</span>  <span class="n">grad</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">pmean</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="s1">&#39;batch&#39;</span><span class="p">)</span></span>
   <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradient</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
   <span class="n">metrics</span> <span class="o">=</span> <span class="n">compute_metrics</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span style="background-color: rgba(0, 255, 0, 0.3)"><span class="o">+</span>  <span class="n">metrics</span> <span class="o">=</span> <span class="n">jax</span><span class="o">.</span><span class="n">lax</span><span class="o">.</span><span class="n">pmean</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="s1">&#39;batch&#39;</span><span class="p">)</span></span>
   <span class="k">return</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">metrics</span>
 
<span style="background-color: rgba(128, 128, 128, 0.3)">[...]</span>
 
 <span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">train_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">rng</span><span class="p">):</span>
   <span class="sd">&quot;&quot;&quot;Train for a single epoch.&quot;&quot;&quot;</span>
<span style="background-color: rgba(0, 255, 0, 0.3)"><span class="o">+</span>  <span class="k">if</span> <span class="n">batch_size</span> <span class="o">%</span> <span class="n">jax</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span></span>
<span style="background-color: rgba(0, 255, 0, 0.3)"><span class="o">+</span>    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Batch size must be divisible by the number of devices&#39;</span><span class="p">)</span></span>
<span style="background-color: rgba(0, 255, 0, 0.3)"><span class="o">+</span></span>
   <span class="n">train_ds_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_ds</span><span class="p">[</span><span class="s1">&#39;image&#39;</span><span class="p">])</span>
   <span class="n">steps_per_epoch</span> <span class="o">=</span> <span class="n">train_ds_size</span> <span class="o">//</span> <span class="n">batch_size</span>
 
<span style="background-color: rgba(128, 128, 128, 0.3)">[...]</span>
   <span class="n">batch_metrics</span> <span class="o">=</span> <span class="p">[]</span>
   <span class="k">for</span> <span class="n">perm</span> <span class="ow">in</span> <span class="n">perms</span><span class="p">:</span>
     <span class="n">batch</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="p">[</span><span class="n">perm</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">train_ds</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
<span style="background-color: rgba(0, 255, 0, 0.3)"><span class="o">+</span>    <span class="n">batch</span> <span class="o">=</span> <span class="n">shard</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span></span>
     <span class="n">optimizer</span><span class="p">,</span> <span class="n">metrics</span> <span class="o">=</span> <span class="n">train_step</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">batch</span><span class="p">)</span>
     <span class="n">batch_metrics</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>
 
<span style="background-color: rgba(128, 128, 128, 0.3)">[...]</span>
   <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
     <span class="n">optimizer</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">train_epoch</span><span class="p">(</span>
         <span class="n">optimizer</span><span class="p">,</span> <span class="n">train_ds</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="n">input_rng</span><span class="p">)</span>
<span style="background-color: rgba(255, 0, 0, 0.3)"><span class="o">-</span>    <span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">eval_model</span><span class="p">(</span><span class="n">optimizer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">test_ds</span><span class="p">)</span></span>
<span style="background-color: rgba(0, 255, 0, 0.3)"><span class="o">+</span>    <span class="n">model</span> <span class="o">=</span> <span class="n">jax_utils</span><span class="o">.</span><span class="n">unreplicate</span><span class="p">(</span><span class="n">optimizer</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>  <span class="c1"># Fetch from 1st device</span></span>
<span style="background-color: rgba(0, 255, 0, 0.3)"><span class="o">+</span>    <span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">=</span> <span class="n">eval_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">test_ds</span><span class="p">)</span></span>
     <span class="n">logging</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s1">&#39;eval epoch: </span><span class="si">%d</span><span class="s1">, loss: </span><span class="si">%.4f</span><span class="s1">, accuracy: </span><span class="si">%.2f</span><span class="s1">&#39;</span><span class="p">,</span>
                  <span class="n">epoch</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span>
   <span class="k">return</span> <span class="n">optimizer</span>
</pre></div></div>
